{
  "hash": "8fa6ea8bf4d92d29d642c997cfc17b3c",
  "result": {
    "markdown": "---\ntitle: \"Food Waste Analysis\"\ndescription: \"Researching if there is a relationship between the amount of food waste produced and household income\"\nauthor: \n  - name: Ruth Enriquez\n    url: {}\ndate: 2022-12-5\ncategories: [MEDS, R, Statistics, Food Waste, California]\nimage: food_waste.JPG\ndraft: false\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show the code\"\nbase_url: https://ruthe808.github.io\n---\n\n\n## Question\n\nI wanted to look at the relationship between food waste production and household income, specifically do households with higher income produce more food waste? I wanted to investigate this relationship because 10% of American's suffer from food insecurity, yet every year we waste 40% of all food. Of the food waste produced in America 31% of it is produced at the wholesale & retail level. I wanted to see if there was an opportunity to divert edible food waste/excess to individuals instead of landfills. I think this is an important topic to investigate because everyone should have access to food. This topic is also important because reducing the amount of food waste in landfills can help reduce the amount of methane produced and help to mitigate climate change. Doing a quick google search, I see there are others wondering about the effects of socioeconomic status on food waste production. There is a research paper, ([Community social capital and status: The social dilemma of food waste](https://www.sciencedirect.com/science/article/pii/S0921800921000124#:~:text=More%20specifically%2C%20in%20areas%20where,related%20to%20lower%20food%20waste.)), that look at the negative relationship food waste levels have related to local levels of social capital in Italy. However, I couldn't find other's asking a similar question for America. Though there seems to be a growing interest in food waste data and statistics. I think there is still a gap in the data collection of food waste produced in America therefore there isn't a existing evidence on the question of do households with higher income produce more food waste in America.\n\n## Data\n\nI got my food waste data from the ([Environmental Protection Agency](https://edg.epa.gov/data/PUBLIC/R9/ExcessFoodPublic_USTer_2020_R9.gdb.zip))(EPA) & my household income data from the ([United States Census Bureau](https://data.census.gov/table?q=DP03&t=Earnings+(Individuals):Income+(Households,+Families,+Individuals):Income+and+Earnings&g=0100000US_0400000US06$0500000&y=2020&tid=ACSDP5Y2020.DP03&tp=false)). For this project, I decided to shrink my scope & to focus on food waste produced at the wholesale & retail level & household income in California counties.\n\nI quickly learned that most companies do not rigorously track food waste, so all the numbers I used from the EPA data are estimates. From the data the EPA was able to collect they ran it through an algorithm that produced low and high estimates of food wasted for the year. There was little transparency on how the EPA calculated the low and high food waste estimates. With this limitation, I decided to apply my analysis to both estimates provided to see if there was a relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(sjPlot)\nlibrary(rempsyc)\nlibrary(broom)\n\n# Set your filepaths here! Or, set this up as an .Rproj if you'd like.\nrootdir <- (\"C:/Users/ruthe/Documents/F22/EDS222/statsFoodWaste\")\ndatadir <- file.path(rootdir,\"data\")\n#setwd(file.path(rootdir,\"homework\",\"assignment-02-ruthe808\"))\n\n#loading food waste data on wholesale and retail \nfoodRaw <- read_excel(file.path(datadir, \"foodWaste\", file = \"Food_Wholesale_Retail.xlsx\"), sheet = \"Data\") |> \n  clean_names() |> \n  mutate(excessfood_tonyear_lowest = as.numeric(excessfood_tonyear_lowest), excessfood_tonyear_highest = as.numeric(excessfood_tonyear_highest)) |> \n  filter(is.na(excessfood_tonyear_lowest) == FALSE, is.na(excessfood_tonyear_highest) == FALSE, county != \"NULL\")\n\n#loading in CA county & income census data\nCensus <- read_excel(file.path(datadir, file = \"census2020.xlsx\"), sheet = \"Data2\") |> \n  clean_names()\n\nfood <- foodRaw |> \n  select(\"county\", \"state\", \"excessfood_tonyear_lowest\", \"excessfood_tonyear_highest\") |> \n  filter(state == \"CA\") |> \n  group_by(county) |> \n  summarise(Mean_Food_Waste_Low = mean(excessfood_tonyear_lowest), Mean_Food_Waste_High = mean(excessfood_tonyear_highest))\n\n#joining the food and census tables together\nfoodCensus <- left_join(Census, food, by = \"county\") |> \n  select(\"county\",\n         \"mean_household_income_dollars\",\n         \"Mean_Food_Waste_Low\",\n         \"Mean_Food_Waste_High\")\n\n#loading in county by region data\nregion <- read_excel(file.path(datadir, file = \"countyRegion.xlsx\"))\n\n\n#Making a region/county data frame with food waste data\n#Use later for getting count to calculate pvalue\nfoodRegion<- left_join(foodCensus, region, by = \"county\")\n\n#Looking at regional trend for LOW estimate\nfoodRegionLow<- left_join(foodCensus, region, by = \"county\") |> \n  group_by(Region) |> \n  summarise(Mean_Low = mean(Mean_Food_Waste_Low),\n            SD_Low = sd(Mean_Food_Waste_Low))\n\n#Looking at regional trend for HIGH estimate\nfoodRegionHigh<- left_join(foodCensus, region, by = \"county\") |> \n  group_by(Region) |> \n  summarise(Mean_High = mean(Mean_Food_Waste_High),\n            SD_High = sd(Mean_Food_Waste_High))\n```\n:::\n\n\n## Exploring my Data\n\n### Checking my data distribution\n\nI decided to look at how my data was distributed by plotting it on a histogram. After some data wrangling this was the best, I could normalize my data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#checking my data distribution\n#incomeHist <- hist(foodCensus$mean_household_income_dollars)\n\nincomeHist <- ggplot(data = foodCensus)+\n  geom_histogram(aes(x =mean_household_income_dollars), fill = \"cyan4\", bins = 8)+\n  theme_classic()+\n  labs(title = \"Histogram of Mean Household Income in Dollars\",\n       x = \"Mean Household Income ($)\")\n  \n#lowHist <- hist(foodCensus$Mean_Food_Waste_Low)\nlowHist <- ggplot(data = foodCensus)+\n  geom_histogram(aes(x = Mean_Food_Waste_Low), fill = \"cyan4\", bins = 8)+\n  theme_classic()+\n  labs(title = \"Histogram of Mean Food Waste Low Estimate\",\n       x = \"Mean Food Waste (Tons)\")\n\n#highHist <- hist(foodCensus$Mean_Food_Waste_High)\nhighHist <- ggplot(data = foodCensus)+\n  geom_histogram(aes(x = Mean_Food_Waste_High), fill = \"cyan4\", bins = 8)+\n  theme_classic()+\n  labs(title = \"Histogram of Mean Food Waste High Estimate\",\n       x = \"Mean Food Waste (Tons)\")\n\nincomeHist\n```\n\n::: {.cell-output-display}\n![](food_waste_stats_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlowHist\n```\n\n::: {.cell-output-display}\n![](food_waste_stats_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhighHist\n```\n\n::: {.cell-output-display}\n![](food_waste_stats_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n:::\n\n\n### Is this there an obvious relationship?\n\nOut of curiosity I also plotted my data in a scatter plot to see if there was an obvious relationship between food waste production and household income. For the low food waste estimate there didn't seem to be a relationship, while the high food waste estimate seemed to have a positive relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#initially checking if there is a relationship between average household income and average food waste produced\nlowWaste <- ggplot(data = foodCensus,\n                            aes(x = mean_household_income_dollars,\n                                y = Mean_Food_Waste_Low)) +\n  geom_point(size = 3) +\n  theme_classic() +\n  labs(x = \"Mean Food Waste Low (tons)\",\n       y = \"Mean Household Income ($)\")\n\nlowWaste\n```\n\n::: {.cell-output-display}\n![](food_waste_stats_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhighWaste <- ggplot(data = foodCensus,\n                            aes(x = mean_household_income_dollars,\n                                y = Mean_Food_Waste_High)) +\n  geom_point(size = 3) +\n  theme_classic() +\n  labs(x = \"Mean Food Waste High (tons)\",\n       y = \"Mean Household Income ($)\")\n\n\nhighWaste\n```\n\n::: {.cell-output-display}\n![](food_waste_stats_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n## Analysis Plan\n\nAfter exploring my data, I wanted to see if there really a relationship between the food waste was estimates and household incomes. To investigate this relationship further I decided that I wanted to run a linear regression model and do hypothesis testing. Part of the reason why I decided to do these analyses is because of the limitations I had with the data available. With the limited amount of data, I had I wasn't able to do other analyses.\n\n## Running Linear Regressions\n\n### Visualizing Linear Regressions\n\n#### Low Food Waste Estimate\n\n\n$$\\text{food waste low}_i = \\beta_0 + \\beta_1 \\text{mean household income}_i + \\varepsilon_i$$\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating a linear regression on LOW food waste estimate\nregLow <-lm(Mean_Food_Waste_Low ~ mean_household_income_dollars, data =foodCensus)\ntab_model(regLow)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Mean Food Waste Low</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.54</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.44&nbsp;&ndash;&nbsp;4.64</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">mean household income<br>dollars</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00&nbsp;&ndash;&nbsp;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.733</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">58</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.002 / -0.016</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plotting linear regression for LOW food waste estimate\nlowWastePlot <- ggplot(data = foodCensus,\n                       aes(x = mean_household_income_dollars,\n                           y = Mean_Food_Waste_Low)) +\n  labs(x = \"Mean Household Income ($)\",\n      y = \"Food Waste Low Estimate (tons)\") +\n  geom_point(alpha = 0.5, size = 3) + \n  geom_smooth(method ='lm', \n              formula = y~x, \n              color =\"lightcoral\", \n              se = F, size = 1.5) +\n  theme_classic()\n\nlowWastePlot\n```\n\n::: {.cell-output-display}\n![](food_waste_stats_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWhen I ran the linear regression for the low food waste estimate, it showed that as household income increased there was a slight decrease in the amount of food waste produced. However, with such a high p-value, the mapped relationship is not significance. I do not have confidence to accept this relationship.\n\n#### High Food Waste Estimate\n\n\n$$\\text{food waste high}_i = \\beta_0 + \\beta_1 \\text{mean household income}_i + \\varepsilon_i$$\n\n::: {.cell}\n\n```{.r .cell-code}\n#Creating a linear regression on HIGH food waste estimate\nregHigh <-lm(Mean_Food_Waste_High ~ mean_household_income_dollars, data =foodCensus)\ntab_model(regHigh)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Mean Food Waste High</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">122.45</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">118.26&nbsp;&ndash;&nbsp;126.63</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">mean household income<br>dollars</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">58</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.193 / 0.178</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Plotting linear regression for HIGH food waste estimate\nhighWastePlot <- ggplot(data = foodCensus,\n                        aes(x = mean_household_income_dollars,\n                            y = Mean_Food_Waste_High)) +\n  labs(x = \"Mean Household Income ($)\",\n      y = \"Food Waste High Estimate (tons)\") +\n  geom_point(alpha = 0.5, size = 3) + \n  geom_smooth(method ='lm',\n              formula = y~x,\n              color =\"lightcoral\",\n              se = F,\n              size = 1.5) +\n  theme_classic()\n\nhighWastePlot\n```\n\n::: {.cell-output-display}\n![](food_waste_stats_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWhen I ran a linear regression on the high food waste estimates, the data said the opposite. As household income increased the increase in production of food waste was more significant for this data. In this model the p-value was much better, and the mapped relationship is significant. I would have more confidence accepting this relationship if both estimates were producing similar results with similar p-values.\n\n## Hypothesis Testing\n\nI wanted to continue my analysis by doing a t.test. I chose two different regions in California with varying average household incomes. I chose to the Northern San Joaquin Valley region with an average household income of about 75,000 dollars & the San Francisco Bay Area region with an average household income of about 156,000 dollars. I wanted to see how the relationship between the two regions within the two different estimates.\n\n### Low\n\n\n$$H_{0}: \\mu_{SoSJ} - \\mu_{SfBay} = 0$$ $$H_{A}: \\mu_{SoSJ} - \\mu_{SfBay} \\neq 0$$\n\n::: {.cell}\n\n```{.r .cell-code}\n#Computing point estimate of your parameter of interest\n#finding the mean inputs for the point estimate calculation\nmuSoSjL <- (foodRegionLow$Mean_Low[foodRegionLow$Region==\"Southern San Joaquin Valley\"])\nmuSfBayL <- (foodRegionLow$Mean_Low[foodRegionLow$Region==\"San Francisco Bay Area\"])\n\n#calculating point estimate\npointEstL = round(as.numeric(muSoSjL - muSfBayL) , 3)\n\n#calculating standard error\ncountSoSj = foodRegion |> \n  filter(Region == \"Southern San Joaquin Valley\") |> \n  count()\ncountSfBay = foodRegion |> \n  filter(Region == \"San Francisco Bay Area\") |> \n  count()\n\n#calling out the standard deviation\nsdSoSjL <- (foodRegionLow$SD_Low[foodRegionLow$Region==\"Southern San Joaquin Valley\"])\nsdSfBayL <- (foodRegionLow$SD_Low[foodRegionLow$Region==\"San Francisco Bay Area\"])\n\n#calculating standard error\nseFoodL = round(as.numeric(sqrt(sdSoSjL^2/countSoSj + sdSfBayL^2/countSfBay)),3)\n\n#calculating test statistic/zscore\nzScoreL = round(((pointEstL - 0)/seFoodL),3)\n\n#calculating our p-value using pt\npvalL <- pt(zScoreL, 26, lower.tail = FALSE)\n\n#Doing a t.test to check my work\nt1 <- t.test(foodRegion$Mean_Food_Waste_Low[foodRegion$Region==\"Southern San Joaquin Valley\"], foodRegion$Mean_Food_Waste_Low[foodRegion$Region==\"San Francisco Bay Area\"])\n\nstats.table <- tidy(t1, conf.int = TRUE)\nnice_table(stats.table, broom = \"t.test\")\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-8ff90d8e{table-layout:auto;}.cl-8fe37370{font-family:'Times New Roman';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-8fe3738e{font-family:'Times New Roman';font-size:12pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-8fe373a2{font-family:'Times New Roman';font-size:7.2pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3.6pt;}.cl-8febada6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-8febdcf4{background-color:transparent;vertical-align: middle;border-bottom: 0.5pt solid rgba(0, 0, 0, 1.00);border-top: 0.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-8febdd12{background-color:transparent;vertical-align: middle;border-bottom: 0.5pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-8ff90d8e'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">Method</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">Alternative</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">Mean 1</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">Mean 2</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe3738e\">M</span><span class=\"cl-8fe373a2\">1</span><span class=\"cl-8fe37370\"> - </span><span class=\"cl-8fe3738e\">M</span><span class=\"cl-8fe373a2\">2</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe3738e\">t</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe3738e\">df</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe3738e\">p</span></p></th><th class=\"cl-8febdcf4\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">95% CI</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">Welch Two Sample t-test</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">two.sided</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">3.73</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">3.18</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">0.56</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">0.96</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">9.00</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">.361</span></p></td><td class=\"cl-8febdd12\"><p class=\"cl-8febada6\"><span class=\"cl-8fe37370\">[-0.75, 1.87]</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nAfter running the t.test on the low food waste estimates I observed that there was a slight difference in the means. But with our p-value at 0.361 I would fail to reject the null hypothesis. For the low food waste estimates, I would fail to reject the null hypothesis. And for the high food waste estimates I would reject the null hypothesis.\n\n### High\n\n\n$$H_{0}: \\mu_{SoSJ} - \\mu_{SfBay} = 0$$ $$H_{A}: \\mu_{SoSJ} - \\mu_{SfBay} \\neq 0$$\n\n::: {.cell}\n\n```{.r .cell-code}\n#Computing point estimate of your parameter of interest\n#finding the mean inputs for the point estimate calculation\nmuSoSj <- (foodRegionHigh$Mean_High[foodRegionHigh$Region==\"Southern San Joaquin Valley\"])\nmuSfBay <- (foodRegionHigh$Mean_High[foodRegionHigh$Region==\"San Francisco Bay Area\"])\n\n#calculating point estimate\npointEst = round(as.numeric(muSoSj - muSfBay) , 3)\n\n#calling out the standard deviation\nsdSoSj <- (foodRegionHigh$SD_High[foodRegionHigh$Region==\"Southern San Joaquin Valley\"])\nsdSfBay <- (foodRegionHigh$SD_High[foodRegionHigh$Region==\"San Francisco Bay Area\"])\n\n#calculating standard error\nseFood = round(as.numeric(sqrt(sdSoSj^2/countSoSj + sdSfBay^2/countSfBay)),3)\n\n#calculating test statistic/zscore\nzScore = round(((pointEst - 0)/seFood),3)\n\n#calculating our p-value using pt\npval <- pt(zScore, 26, lower.tail = FALSE)\n\n#Doing a t.test to check my work\nt2 <- t.test(foodRegion$Mean_Food_Waste_High[foodRegion$Region==\"Southern San Joaquin Valley\"], foodRegion$Mean_Food_Waste_High[foodRegion$Region==\"San Francisco Bay Area\"])\n\nstats.table <- tidy(t2, conf.int = TRUE)\nnice_table(stats.table, broom = \"t.test\")\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"tabwid\"><style>.cl-9048a1e6{table-layout:auto;}.cl-903423c4{font-family:'Times New Roman';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-903423d8{font-family:'Times New Roman';font-size:12pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-903423e2{font-family:'Times New Roman';font-size:7.2pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3.6pt;}.cl-903ad412{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-903b02e8{background-color:transparent;vertical-align: middle;border-bottom: 0.5pt solid rgba(0, 0, 0, 1.00);border-top: 0.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-903b02fc{background-color:transparent;vertical-align: middle;border-bottom: 0.5pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-9048a1e6'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">Method</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">Alternative</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">Mean 1</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">Mean 2</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423d8\">M</span><span class=\"cl-903423e2\">1</span><span class=\"cl-903423c4\"> - </span><span class=\"cl-903423d8\">M</span><span class=\"cl-903423e2\">2</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423d8\">t</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423d8\">df</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423d8\">p</span></p></th><th class=\"cl-903b02e8\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">95% CI</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">Welch Two Sample t-test</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">two.sided</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">129.15</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">132.87</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">-3.72</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">-2.95</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">8.69</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">.017</span></p></td><td class=\"cl-903b02fc\"><p class=\"cl-903ad412\"><span class=\"cl-903423c4\">[-6.59, -0.85]</span></p></td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nRunning the t.test on the high food waste estimates I observed that there was a greater difference in the means, but we had a p-value of 0.015. Once again, the p-value for the high food waste estimate was better than the low p-value.\n\n## Future Work\n\nOverall, after my analyses I do not think I can confidently answer my question. The first reason why I cannot answer my question is the data itself. The data is based off estimates ran from an algorithm that had no transparency to how they were calculated. Second, the two estimates tell different stories and there isn't enough information for me to know if the difference in story is due to how each estimate was calculated. The third reason I cannot answer my question is the p-values for the low estimate were not good. If I were to do this over again, I would hope that there would be actual food waste data and not estimates. I think having actual food waste data would help significantly. I think also having data for more than a year would also be helpful. Having more data would show more trends. It would also give me an opportunity to do a time series analysis.\n",
    "supporting": [
      "food_waste_stats_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/tabwid-1.1.2/tabwid.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}